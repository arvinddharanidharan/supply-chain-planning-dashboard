name: Daily ETL Pipeline

on:
  schedule:
    # Run every day at 6:00 AM UTC (adjust timezone as needed)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write

jobs:
  etl-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install pandas numpy psycopg2-binary sqlalchemy streamlit datetime
        
    - name: Run ETL Pipeline
      env:
        GITHUB_ACTIONS: true
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        DB_PORT: ${{ secrets.DB_PORT }}
      run: |
        echo "Running automated ETL pipeline..."
        python etl_data_generator.py
        echo "ETL completed. Data files updated."
        
    - name: Show data stats
      run: |
        echo "Data Statistics After ETL:"
        echo "Orders: $(wc -l < data/orders.csv) records"
        echo "Suppliers: $(wc -l < data/suppliers.csv) records"
        echo "Products: $(wc -l < data/products.csv) records"
        echo "Inventory: $(wc -l < data/inventory.csv) records"
        
    - name: Commit updated data
      uses: stefanzweifel/git-auto-commit-action@v4
      with:
        commit_message: 'Automated ETL: Daily supply chain data update'
        file_pattern: 'data/*.csv logs/*.txt'
        commit_user_name: 'ETL Pipeline'
        commit_user_email: 'etl@supply-chain-dashboard.com'
